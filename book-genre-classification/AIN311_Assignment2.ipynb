{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4015a29-4bed-49c7-b577-46548f26cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sklearn\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "from abc import ABCMeta, abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8bac9c-74e7-4543-9abb-518af1d4b8b1",
   "metadata": {},
   "source": [
    "## 1. Understanding the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1704875d-73cc-4150-b572-952be603cf71",
   "metadata": {},
   "source": [
    "**Question:** You will be predicting the genre of a book by the book’s description. Is that feasible? Give 3 examples of specific keywords that may be useful, together with statistics on how often they appear in the book description may help to predict its genre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b00527-e6d6-4212-a672-f831b85d90d5",
   "metadata": {},
   "source": [
    "**Answer:** Predicting the genre of a book solely from its description seems like a daunting task at first, but it should be feasible given the importance of finding genre-specific words that will help us to easily identify a genre of any given book. First, we should see whether we can find such words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a7d5eaa-019f-4e20-b045-7f7be1260c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(\"book_dataset_a2.csv\", delimiter = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "587bc51a-6546-413c-afad-15521bbcfca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "      <th>coverImg</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré (Illustrator)</td>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>Classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Jane Austen, Anna Quindlen (Introduction)</td>\n",
       "      <td>Alternate cover edition of ISBN 9780679783268S...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>Classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>About three things I was absolutely positive.\\...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21074</th>\n",
       "      <td>Elemental</td>\n",
       "      <td>Kim Richardson (Goodreads Author)</td>\n",
       "      <td>When seventeen-year-old Kara Nightingale is su...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21075</th>\n",
       "      <td>Unbelievable</td>\n",
       "      <td>Sherry Gammon (Goodreads Author)</td>\n",
       "      <td>Lilah Lopez Dreser's in town to take care of u...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21076</th>\n",
       "      <td>Anasazi</td>\n",
       "      <td>Emma Michaels</td>\n",
       "      <td>'Anasazi', sequel to 'The Thirteenth Chime' by...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>Mystery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21077</th>\n",
       "      <td>Marked</td>\n",
       "      <td>Kim Richardson (Goodreads Author)</td>\n",
       "      <td>--READERS FAVORITE AWARDS WINNER 2011--Sixteen...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21078</th>\n",
       "      <td>Wayward Son</td>\n",
       "      <td>Tom Pollack (Goodreads Author), John Loftus (G...</td>\n",
       "      <td>A POWERFUL TREMOR UNEARTHS AN ANCIENT SECRETBu...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21079 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0                               The Hunger Games   \n",
       "1      Harry Potter and the Order of the Phoenix   \n",
       "2                          To Kill a Mockingbird   \n",
       "3                            Pride and Prejudice   \n",
       "4                                       Twilight   \n",
       "...                                          ...   \n",
       "21074                                  Elemental   \n",
       "21075                               Unbelievable   \n",
       "21076                                    Anasazi   \n",
       "21077                                     Marked   \n",
       "21078                                Wayward Son   \n",
       "\n",
       "                                                  author  \\\n",
       "0                                        Suzanne Collins   \n",
       "1              J.K. Rowling, Mary GrandPré (Illustrator)   \n",
       "2                                             Harper Lee   \n",
       "3              Jane Austen, Anna Quindlen (Introduction)   \n",
       "4                                        Stephenie Meyer   \n",
       "...                                                  ...   \n",
       "21074                  Kim Richardson (Goodreads Author)   \n",
       "21075                   Sherry Gammon (Goodreads Author)   \n",
       "21076                                      Emma Michaels   \n",
       "21077                  Kim Richardson (Goodreads Author)   \n",
       "21078  Tom Pollack (Goodreads Author), John Loftus (G...   \n",
       "\n",
       "                                             description  \\\n",
       "0      WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...   \n",
       "1      There is a door at the end of a silent corrido...   \n",
       "2      The unforgettable novel of a childhood in a sl...   \n",
       "3      Alternate cover edition of ISBN 9780679783268S...   \n",
       "4      About three things I was absolutely positive.\\...   \n",
       "...                                                  ...   \n",
       "21074  When seventeen-year-old Kara Nightingale is su...   \n",
       "21075  Lilah Lopez Dreser's in town to take care of u...   \n",
       "21076  'Anasazi', sequel to 'The Thirteenth Chime' by...   \n",
       "21077  --READERS FAVORITE AWARDS WINNER 2011--Sixteen...   \n",
       "21078  A POWERFUL TREMOR UNEARTHS AN ANCIENT SECRETBu...   \n",
       "\n",
       "                                                coverImg        genre  \n",
       "0      https://i.gr-assets.com/images/S/compressed.ph...  Young Adult  \n",
       "1      https://i.gr-assets.com/images/S/compressed.ph...      Fantasy  \n",
       "2      https://i.gr-assets.com/images/S/compressed.ph...     Classics  \n",
       "3      https://i.gr-assets.com/images/S/compressed.ph...     Classics  \n",
       "4      https://i.gr-assets.com/images/S/compressed.ph...  Young Adult  \n",
       "...                                                  ...          ...  \n",
       "21074  https://i.gr-assets.com/images/S/compressed.ph...      Fantasy  \n",
       "21075  https://i.gr-assets.com/images/S/compressed.ph...      Romance  \n",
       "21076  https://i.gr-assets.com/images/S/compressed.ph...      Mystery  \n",
       "21077  https://i.gr-assets.com/images/S/compressed.ph...      Fantasy  \n",
       "21078  https://i.gr-assets.com/images/S/compressed.ph...      Fiction  \n",
       "\n",
       "[21079 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc877ef-6a62-4e58-92d6-6340d2325014",
   "metadata": {},
   "source": [
    "Here we have the description column which is full of string descriptions of the 21079 books we have in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "808f3de3-7c11-458e-8fb8-34dcb6146314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...\n",
       "1        There is a door at the end of a silent corrido...\n",
       "2        The unforgettable novel of a childhood in a sl...\n",
       "3        Alternate cover edition of ISBN 9780679783268S...\n",
       "4        About three things I was absolutely positive.\\...\n",
       "                               ...                        \n",
       "21074    When seventeen-year-old Kara Nightingale is su...\n",
       "21075    Lilah Lopez Dreser's in town to take care of u...\n",
       "21076    'Anasazi', sequel to 'The Thirteenth Chime' by...\n",
       "21077    --READERS FAVORITE AWARDS WINNER 2011--Sixteen...\n",
       "21078    A POWERFUL TREMOR UNEARTHS AN ANCIENT SECRETBu...\n",
       "Name: description, Length: 21079, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d7b984-9a47-49b8-899e-5269df5cf699",
   "metadata": {},
   "source": [
    "### Examples of some specific keywords that may be useful for the 'Fantasy' genre:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fbe704-cffa-4fb3-a6cc-98050176e78d",
   "metadata": {},
   "source": [
    "Now let's look at some words which could be important for the 'Fantasy' genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4413f701-ae8a-47ec-a623-43404e2259c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCountinGenre (wordTosearch, genreOfchoice):\n",
    "    true = 0\n",
    "    for i,desc in enumerate(books['description']):\n",
    "        if ((books[\"genre\"][i] == genreOfchoice) & (wordTosearch in desc)):\n",
    "            true += 1\n",
    "    return(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f5c9d5e-987b-4203-901a-7d1c8f515e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "possibleImportantWordsforFantasy = ['wand','sword','shield','magic','king','elf','dragon','dwarf','kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e9a3d6a-ee8a-4c7f-a243-5dfe9994f38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of some words in the Fantasy genre:\n",
      "wand count: 65\n",
      "sword count: 238\n",
      "shield count: 25\n",
      "magic count: 1399\n",
      "king count: 1563\n",
      "elf count: 1167\n",
      "dragon count: 359\n",
      "dwarf count: 38\n",
      "kingdom count: 423\n"
     ]
    }
   ],
   "source": [
    "print('Number of some words in the Fantasy genre:')\n",
    "for word in possibleImportantWordsforFantasy:\n",
    "    print(word, 'count:', wordCountinGenre (word, \"Fantasy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b93e7b8-a115-49ee-a984-7585b76db69c",
   "metadata": {},
   "source": [
    "As we can see from the above experiment, top 3 most popular words are: **king** with **1563** times, **magic** with **1399** times, and **elf** with **1167** times occured in the descriptions of fantasy books we have in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e295b7e8-a606-4e11-9ece-ecbe0b3afc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "descriptions, descriptions_test = train_test_split(books[\"description\"], test_size = 0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38ea4f38-b841-40e7-9dae-3acad89f94df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,description in enumerate(descriptions):\n",
    "    descriptions[i] = description.lower()\n",
    "    descriptions[i] = re.sub('[^a-z]',' ',descriptions[i])\n",
    "    descriptions[i] = re.sub('/  +/g',' ',descriptions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85948802-254b-4ee5-8299-556c085d9560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16863"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8374aa10-be51-49e4-9f3f-968466b1d269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4216"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descriptions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba233ef5-fdf8-4015-b8f6-3d1f72c14458",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_all_words = {}\n",
    "for i in range(len(descriptions)):\n",
    "    words = descriptions[i].split()\n",
    "    for j in range(len(words)):\n",
    "        try:\n",
    "            count  = bag_of_all_words[str(words[j])]\n",
    "            count += 1\n",
    "            bag_of_all_words.update({str(words[j]):count})\n",
    "        except:\n",
    "            bag_of_all_words[str(words[j])] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e298e5e-d540-4a5c-a988-734863eec761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def printDict(dictionary, length = 1):\n",
    "    for i in range(length):\n",
    "        key = list(dictionary)[i]\n",
    "        val = list(dictionary.values())[i]\n",
    "        print(key,':',val)\n",
    "        time.sleep(10*0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37de8379-c816-41b6-93c1-1044fc632b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66083"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bag_of_all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "134a1fa3-2e2a-4eab-b023-048a3bf4fb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winning : 533\n",
      "means : 673\n",
      "fame : 158\n",
      "and : 86053\n",
      "fortune : 256\n",
      "losing : 293\n",
      "certain : 341\n",
      "death : 2242\n",
      "the : 145032\n",
      "hunger : 128\n"
     ]
    }
   ],
   "source": [
    "printDict(bag_of_all_words,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "218fd1b1-56c8-4861-bae4-7a423032ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = books[\"genre\"].unique()\n",
    "bagOfbagsUnigram = dict.fromkeys(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8095b903-dc81-4c84-b39f-aad974e54874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Young Adult': None,\n",
       " 'Fantasy': None,\n",
       " 'Classics': None,\n",
       " 'Science Fiction': None,\n",
       " 'Fiction': None,\n",
       " 'Horror': None,\n",
       " 'Romance': None,\n",
       " 'Mystery': None,\n",
       " 'History': None,\n",
       " 'Thriller': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagOfbagsUnigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43e5a659-8e75-4c03-9e3a-03bb6bfc1f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create nested dictionary for unigram method aptly named 'bag of bag' \n",
    "# because it is a big bag with smaller bag of words for different genres\n",
    "for i in range(len(descriptions)):\n",
    "    genre = books[\"genre\"][i]\n",
    "    bag_of_words = bagOfbagsUnigram[str(genre)]\n",
    "    if (bag_of_words == None):\n",
    "        bag_of_words = {}\n",
    "    words = descriptions[i].split()\n",
    "    for j in range(len(words)):\n",
    "        try:\n",
    "            count = bag_of_words[str(words[j])]\n",
    "            count += 1\n",
    "            bag_of_words.update({str(words[j]):count})\n",
    "        except:\n",
    "            bag_of_words[str(words[j])] = 0\n",
    "    bagOfbagsUnigram[str(genre)] = bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f5bf900-bb58-4fbc-a0a0-b83656dde116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winning : 83\n",
      "means : 156\n",
      "fame : 18\n",
      "and : 11312\n",
      "fortune : 17\n"
     ]
    }
   ],
   "source": [
    "printDict(bagOfbagsUnigram['Young Adult'],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d296b1d-da8a-41bd-a59d-bee433bde7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the : 6230\n",
      "unforgettable : 20\n",
      "novel : 317\n",
      "of : 4342\n",
      "a : 2601\n"
     ]
    }
   ],
   "source": [
    "printDict(bagOfbagsUnigram['Classics'],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1e95e2e-3b8e-4e69-bb75-c7bca7ff1dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set : 163\n",
      "amid : 16\n",
      "the : 14670\n",
      "austere : 0\n",
      "beauty : 136\n"
     ]
    }
   ],
   "source": [
    "printDict(bagOfbagsUnigram['Romance'],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a324f376-48a9-4369-ad86-db229411c48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.919e+03, 0.000e+00, 0.000e+00, ..., 2.000e+00, 0.000e+00,\n",
       "        1.000e+00]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec = DictVectorizer()\n",
    "vector = vec.fit_transform(bagOfbagsUnigram['Romance']).toarray()\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c441af3-c26b-473a-a27c-2d5f571e716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnSizeofClasses (bagOfbagsUnigram):\n",
    "    total_size_of_classes = dict.fromkeys(bagOfbagsUnigram.keys(),0)\n",
    "    for genre in bagOfbagsUnigram.keys():\n",
    "        genreBag = bagOfbagsUnigram[genre]\n",
    "        size_of_class = 0 \n",
    "        for count in genreBag.values():\n",
    "            size_of_class += count\n",
    "        total_size_of_classes[genre] = size_of_class\n",
    "    return total_size_of_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3488df-af55-41a5-9e0b-24f82adfb9e7",
   "metadata": {},
   "source": [
    "## 2. Implementing Naive Bayes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d0ed33-45da-482b-a36b-8eb9f79c4efb",
   "metadata": {},
   "source": [
    "We have represented our data with listed approaches and used them to learn a classifier via\n",
    "Naive Bayes algorithm. We have implemented our own Naive Bayes algorithm, as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b87661e-65e9-417e-b4c8-15c767e35151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Young Adult': 334182,\n",
       " 'Fantasy': 551334,\n",
       " 'Classics': 80119,\n",
       " 'Science Fiction': 123970,\n",
       " 'Fiction': 567334,\n",
       " 'Horror': 74828,\n",
       " 'Romance': 342204,\n",
       " 'Mystery': 171763,\n",
       " 'History': 77406,\n",
       " 'Thriller': 50526}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returnSizeofClasses (bagOfbagsUnigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20979e5c-a068-4053-ad06-881af0e64c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayes (bagOfdescription, bagOfbagsUnigram, books):\n",
    "    total_unique_words = len(bag_of_words)\n",
    "    outputDict = dict.fromkeys(bagOfbagsUnigram.keys())\n",
    "    total_size_of_classes = returnSizeofClasses (bagOfbagsUnigram)\n",
    "    N =  books['genre'].count()\n",
    "    for genre in bagOfbagsUnigram.keys():\n",
    "        genreBag = bagOfbagsUnigram[genre]\n",
    "        total_size_of_class = total_size_of_classes[genre] # count(c)\n",
    "        N_c = (books[\"genre\"] == genre).sum()\n",
    "        prior = np.log(float(N_c/N))\n",
    "        for word in bagOfdescription:\n",
    "            try:\n",
    "                word_count_in_class = genreBag[word] # count(w,c)\n",
    "            except:\n",
    "                word_count_in_class = 0\n",
    "            for i in range(int(bagOfdescription[word])):\n",
    "                P_w_c = float(word_count_in_class + 1)/float(total_size_of_class + total_unique_words)\n",
    "                prior += np.log(P_w_c)\n",
    "        #print('Value for ',genre,': ',prior)\n",
    "        outputDict[genre] = prior\n",
    "    max_key = max(outputDict, key=outputDict.get)\n",
    "    return max_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e7792f-39a2-4ce6-8891-3fed44c4dbe4",
   "metadata": {},
   "source": [
    "(Note: We have also used laplace smoothing as can be seen in the '+1' addition on the divident next to **word_count_in_class** variable.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b94bef9-ecc4-4ae8-9c38-515a66e00fa3",
   "metadata": {},
   "source": [
    "Features: We have used Bag of Words (BoW) model which learns a vocabulary from all the\n",
    "documents, then models each document by counting the number of times each word appears.\n",
    "\n",
    "**strTobagOfwordsUnigram** function converts **string** descriptions to **nestedDict** (Unigram) bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6484359f-f203-4917-a2fc-0545cad9eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strTobagOfwordsUnigram (string):\n",
    "    bag_of_words = {}\n",
    "    words = string.split()\n",
    "    for j in range(len(words)):\n",
    "        try:\n",
    "            count  = bag_of_words[str(words[j])]\n",
    "            count += 1\n",
    "            bag_of_words.update({str(words[j]):count})\n",
    "        except:\n",
    "            bag_of_words[str(words[j])] = 0\n",
    "    return bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cee9c89-ee9c-4905-ada2-db61c1cb14a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveBayesResultsUnigram = []\n",
    "for desc in descriptions_test:\n",
    "    NaiveBayesResultsUnigram.append(NaiveBayes(strTobagOfwordsUnigram(desc), bagOfbagsUnigram, books))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f72896b-b813-4d74-8d7f-28aa6110e5d4",
   "metadata": {},
   "source": [
    "## 3. Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9561deb8-e822-4c50-85be-79255ae14ce9",
   "metadata": {},
   "source": [
    "**Question:** Find a few misclassified books and comment on why you think they were hard to classify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3576cebf-84da-478d-b61c-119aa49cea70",
   "metadata": {},
   "source": [
    "**Answer:** Here are three examples of misclassified books:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6de7dcc-5063-4144-807e-85f3a22b59c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(NaiveBayesResultsBigram)):\n",
    "    if (books['genre'][i] != NaiveBayesResultsBigram[i]):\n",
    "        print('='*16)\n",
    "        print('Index of book:',i)\n",
    "        print('Actual book genre:', books['genre'][i])\n",
    "        print('Prediction:', NaiveBayesResultsBigram[i])\n",
    "        count += 1\n",
    "        if (count == 3):\n",
    "            break;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c933f63f-4892-4d49-8607-4392457082ad",
   "metadata": {},
   "source": [
    "**Text Descriptions of the misclassified books:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c985ecce-9bc7-42e2-91ee-7095b9ecb50a",
   "metadata": {},
   "source": [
    "Index of book: 0\n",
    "\n",
    "Actual book genre: Young Adult\n",
    "\n",
    "Prediction: Thriller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32249531-f4d0-4320-8fea-b7e5e9fa3897",
   "metadata": {},
   "outputs": [],
   "source": [
    "books['description'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca71a8b-5333-4aeb-b5a7-2ef96ffe173b",
   "metadata": {},
   "source": [
    "Index of book: 1\n",
    "\n",
    "Actual book genre: Fantasy\n",
    "\n",
    "Prediction: Fiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e81d81d-57f7-46b9-b69f-48a38e310aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "books['description'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f7be95-425c-4da6-b133-7240d3eb0371",
   "metadata": {},
   "source": [
    "Index of book: 2\n",
    "\n",
    "Actual book genre: Classics\n",
    "\n",
    "Prediction: Mystery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fefcaf5-1715-44f7-987d-834331e209eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "books['description'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceafdb5f-0ea0-432f-86ae-de8adc0a97ad",
   "metadata": {},
   "source": [
    "## 4. Modul Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5407df1e-e0ff-42c3-8032-465cface0282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBagofBagforGenre (descriptions,genre,books):\n",
    "    bag_of_words = {}\n",
    "    for i in range(len(descriptions)):\n",
    "        if(genre == books[\"genre\"][i]):\n",
    "            bag_of_words[i] = strTobagOfwordsUnigram(descriptions[i])\n",
    "    return bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d64c136-8e85-4d77-a067-18f1d363de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fantasyBagofBag = createBagofBagforGenre (descriptions,'Fantasy',books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294a04ef-158e-4a06-8c75-82987f5407c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def documentFrequencyforWord (bagOfbagGenre, word):\n",
    "    count = 0\n",
    "    for bagOfword in bagOfbagGenre.values():\n",
    "        if(word in bagOfword.values()):\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf02222-c673-4dfc-b2aa-c75a7ba9e8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfIdfNormalizer (bagOfbagsUnigram,descriptions,books):\n",
    "    bagOfbagsTfidf = dict.fromkeys(genres)\n",
    "    total_size_of_classes = returnSizeofClasses(bagOfbagsUnigram)\n",
    "    for genre in bagOfbagsUnigram.keys():\n",
    "        n = (books[\"genre\"] == genre).sum()\n",
    "        genreBag = bagOfbagsUnigram[genre]\n",
    "        bagOfbagGenre = createBagofBagforGenre (descriptions,genre,books) \n",
    "        bag_of_words = bagOfbagsTfidf[str(genre)]\n",
    "        if (bag_of_words == None):\n",
    "            bag_of_words = {}\n",
    "        for word,count in genreBag.items():\n",
    "            tf = count\n",
    "            df = documentFrequencyforWord(bagOfbagGenre, word)\n",
    "            idf = np.log(float(1 + n) / float(1 + df)) + 1\n",
    "            bag_of_words.update({word: tf*idf })\n",
    "        bagOfbagsTfidf[str(genre)] = bag_of_words\n",
    "    return bagOfbagsTfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e622f36b-d7bd-4e02-936e-af3a5df5343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagOfbagsTfidf = tfIdfNormalizer (bagOfbagsUnigram,descriptions,books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4204284-8428-48f5-9e8b-52fb593e2fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "printDict(bagOfbagsTfidf['Fantasy'], 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc4466c-a791-469a-af76-88ffaa466f24",
   "metadata": {},
   "source": [
    "### a) Analyzing effect of the words on prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813ea906-13f8-4ce6-b652-7f891c13427e",
   "metadata": {},
   "source": [
    "**Top 10 words whose _presence_ most strongly predicts the genre of the book:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcdf54a-cb0e-4002-8c88-a9f1c627a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "print('Words whose presence are the strongest predictors for:')\n",
    "for genre in bagOfbagsUnigram.keys():   \n",
    "    print('='*16)\n",
    "    print(genre, ':')\n",
    "    output = heapq.nlargest(10, bagOfbagsTfidf[genre], key=bagOfbagsTfidf[genre].get)\n",
    "    string = ''\n",
    "    for val in output:\n",
    "        string += (val + ', ')\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c993371-30f2-4de0-80bd-40feee7107db",
   "metadata": {},
   "source": [
    "**Top 10 words whose _absence_ most strongly predicts the genre of the book:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a651c-6518-4787-9609-7df7e0219b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Words whose absence are the strongest predictors for:')\n",
    "for genre in bagOfbagsUnigram.keys():   \n",
    "    print('='*16)\n",
    "    print(genre, ':')\n",
    "    output = heapq.nsmallest(10, bagOfbagsTfidf[genre], key=bagOfbagsTfidf[genre].get)\n",
    "    string = ''\n",
    "    for val in output:\n",
    "        string += (val + ', ')\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05184218-3727-4924-9676-f48cd0b87014",
   "metadata": {
    "tags": []
   },
   "source": [
    "### b) Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a34916a-646f-4448-a185-c496e3360ec6",
   "metadata": {},
   "source": [
    "First we import the set of English stop words from the nltk library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c730d7b4-3840-40e8-accb-bfb13f560e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0a2f90-a0a4-4eb8-aa53-d0f897e326c1",
   "metadata": {},
   "source": [
    "Create a set of stopwords from the list above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1457c-0d2b-4097-bc24-05107da59bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "setOfstopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b60e55-9de9-4c20-a033-9719797858fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "setOfnonStopwordsinFantasy = {}\n",
    "\n",
    "for word,count in bagOfbagsUnigram['Fantasy'].items():   \n",
    "    if (word not in setOfstopWords):\n",
    "        setOfnonStopwordsinFantasy[word] = count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27e02d5-65aa-40ae-8673-74235e23e875",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The 10 non-stop words that most strongly predict that the book genre is ’Fantasy’:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e3b5b-fbb7-4f5a-90bc-4b9594b7f2ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = heapq.nsmallest(10, setOfnonStopwordsinFantasy, key=setOfnonStopwordsinFantasy.get)\n",
    "string = ''\n",
    "for val in output:\n",
    "    string += (val + ', ')\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7319893a-3a4f-4765-8883-f9b2ac1568ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The 10 non-stop words that most strongly predict that the book genre is ’Mystery’:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08642779-072f-4914-8b79-34e425aab257",
   "metadata": {},
   "outputs": [],
   "source": [
    "setOfnonStopwordsinMystery = {}\n",
    "\n",
    "for word,count in bagOfbagsUnigram['Mystery'].items():   \n",
    "    if (word not in setOfstopWords):\n",
    "        setOfnonStopwordsinMystery[word] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b404c7-9083-4474-9c6b-07817b66a842",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = heapq.nsmallest(10, setOfnonStopwordsinMystery, key=setOfnonStopwordsinFantasy.get)\n",
    "string = ''\n",
    "for val in output:\n",
    "    string += (val + ', ')\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca9d4f3-1642-4cba-83e6-13ddbd72c17f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### As we can see in the above results, the non-stop words that most strongly predict a given genre changed drastically from the initial results which included stop words as well in the above section of 4.a."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b3260c-15bc-48cc-b022-e0ab0ebb813f",
   "metadata": {},
   "source": [
    "============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbb7e5f-5915-4346-a697-ee21672c1591",
   "metadata": {},
   "source": [
    "**For example in 4.a, the top 10 words for Fantasy were:**\n",
    "\n",
    "the, and, of, a, to, in, is, her, as, his\n",
    "\n",
    "**Where all the top 10 words can be classified as a stop word. After we exclude the stop words, we can see that we have more meaningful words now compared to 4.a:**\n",
    "\n",
    "corridor, pottter, gryffindor, staples, transcended, chronlogical, unambitious, hobbiton, tattoos, brandishing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77330d45-d7fd-4163-ada0-772f971f691a",
   "metadata": {},
   "source": [
    "============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eefe91-3d0b-4e1a-aa65-cf89d74e2c86",
   "metadata": {},
   "source": [
    "**The top 10 words for Mystery were:**\n",
    "\n",
    "the, a, and, of, to, as, in, is, her, his\n",
    "\n",
    "**Where all the top 10 words can be classified as a stop word. After we exclude the stop words, we can see that we have more meaningful words now compared to 4.a:**\n",
    "\n",
    "dine, overslept, chopping, chopped, hive, bumblebee, stung, chancery, herring, swallowed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66334aa3-4aba-4aa9-91f9-132db7257b1b",
   "metadata": {},
   "source": [
    "### Training the Models again with Stopwords and Calculating their Accuracy:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb763a3-de0d-4ef1-83a8-a9ec0bd58c40",
   "metadata": {},
   "source": [
    "**1. Unigram model with stopwords:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac2596e-b94b-4a82-8bba-ba41d11d7834",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagOfbagsUnigramStopwords = dict.fromkeys(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c151f0d9-4523-494e-a65b-e4c67849f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create nested dictionary for unigram method aptly named 'bag of bag' \n",
    "# because it is a big bag with smaller bag of words for different genres\n",
    "for i in range(len(descriptions)):\n",
    "    genre = books[\"genre\"][i]\n",
    "    bag_of_words = bagOfbagsUnigramStopwords[str(genre)]\n",
    "    if (bag_of_words == None):\n",
    "        bag_of_words = {}\n",
    "    words = descriptions[i].split()\n",
    "    for j in range(len(words)):\n",
    "        if (words[j] not in setOfstopWords):\n",
    "            try:\n",
    "                count = bag_of_words[str(words[j])]\n",
    "                count += 1\n",
    "                bag_of_words.update({str(words[j]):count})\n",
    "            except:\n",
    "                bag_of_words[str(words[j])] = 0\n",
    "    bagOfbagsUnigramStopwords[str(genre)] = bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2413f76d-e5db-41a2-87ec-a4b7f82f8449",
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveBayesResultsUnigramStopwords = []\n",
    "for desc in descriptions_test:\n",
    "    NaiveBayesResultsUnigramStopwords.append(NaiveBayes(strTobagOfwordsUnigram(desc), bagOfbagsUnigramStopwords, books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940c7299-6392-48b0-bf88-88861c71c1dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "overall_accuracy = performanceMeasures (books['genre'],NaiveBayesResultsUnigramStopwords,\"accuracy\")\n",
    "print('Overall Accuracy:',\"{:.2f}\".format(overall_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77176cb5-6491-4b98-baf5-c2749d4bd905",
   "metadata": {},
   "source": [
    "**2. Bigram model with stopwords:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d58e85-dfa4-46da-b4ee-7ea7b9663b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagOfbagsBigramStopwords = dict.fromkeys(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0427519-7e6d-4c19-9c5b-ac8921f078bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create nested dictionary for unigram method aptly named 'bag of bag' \n",
    "# because it is a big bag with smaller bag of words for different genres\n",
    "for i in range(len(descriptions)):\n",
    "    genre = books[\"genre\"][i]\n",
    "    bag_of_words = bagOfbagsBigramStopwords[str(genre)]\n",
    "    if (bag_of_words == None):\n",
    "        bag_of_words = {}\n",
    "    words = descriptions[i].split()\n",
    "    for j in range(len(words)):\n",
    "        if (words[j] not in setOfstopWords):\n",
    "            try:\n",
    "                count = bag_of_words[str(words[j])]\n",
    "                count += 1\n",
    "                bag_of_words.update({str(words[j]):count})\n",
    "            except:\n",
    "                bag_of_words[str(words[j])] = 0\n",
    "    bagOfbagsBigramStopwords[str(genre)] = bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da7524-dc1e-4234-b8c6-3c446fec4338",
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveBayesResultsBigramStopwords = []\n",
    "for desc in descriptions_test:\n",
    "    NaiveBayesResultsBigramStopwords.append(NaiveBayes(strTobagOfwordsBigram(desc), bagOfbagsBigramStopwords, books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838d2170-4c43-4908-b8ad-b4bcafa6ca18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "overall_accuracy = performanceMeasures (books['genre'],NaiveBayesResultsBigramStopwords,\"accuracy\")\n",
    "print('Overall Accuracy:',\"{:.2f}\".format(overall_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973d0eac-8bca-40ab-984c-72c681515eef",
   "metadata": {},
   "source": [
    "**3. Unigram model with TF-IDF without stopwords**\n",
    "\n",
    "**(Words with more tf-idf score than 1000 are removed from the bag of words):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b581d0b1-ba5c-494d-935f-cb3e265ec75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagOfbagsUnigramTfIdfStopwords = dict.fromkeys(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d82bdf7-c845-4165-9b3c-7c84cd3576ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create nested dictionary for unigram method aptly named 'bag of bag' \n",
    "# because it is a big bag with smaller bag of words for different genres\n",
    "for i in range(len(descriptions)):\n",
    "    genre = books[\"genre\"][i]\n",
    "    bag_of_words = bagOfbagsUnigramTfIdfStopwords[str(genre)]\n",
    "    if (bag_of_words == None):\n",
    "        bag_of_words = {}\n",
    "    words = descriptions[i].split()\n",
    "    for j in range(len(words)):\n",
    "        if (words[j] not in setOfstopWords):\n",
    "            try:\n",
    "                count = bag_of_words[str(words[j])]\n",
    "                count += 1\n",
    "                bag_of_words.update({str(words[j]):count})\n",
    "            except:\n",
    "                bag_of_words[str(words[j])] = 0\n",
    "    bagOfbagsUnigramTfIdfStopwords[str(genre)] = bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc6cd2-ee1a-4c61-809d-f99b0ebe080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveBayesResultsUnigramTfIdfStopwords = []\n",
    "for desc in descriptions_test:\n",
    "    NaiveBayesResultsUnigramTfIdfStopwords.append(NaiveBayes(strTobagOfwordsUnigram(desc), bagOfbagsUnigramTfIdfStopwords, books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debd30eb-ab5f-40f8-9faf-97b2c32d028d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "overall_accuracy = performanceMeasures (books['genre'],NaiveBayesResultsUnigramTfIdfStopwords,\"accuracy\")\n",
    "print('Overall Accuracy:',\"{:.2f}\".format(overall_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2840f9-2351-4731-9304-5dd3de3acc33",
   "metadata": {},
   "source": [
    "**4. Unigram model with TF-IDF with stopwords**\n",
    "\n",
    "**(Words with more tf-idf score than 1000 are removed from the bag of words):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de7d82-63e4-4e7a-a71e-ab244d9f62f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagOfbagsUnigramTfIdf = dict.fromkeys(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1573b380-934a-4029-8415-18ff21f29323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create nested dictionary for unigram method aptly named 'bag of bag' \n",
    "# because it is a big bag with smaller bag of words for different genres\n",
    "for i in range(len(descriptions)):\n",
    "    genre = books[\"genre\"][i]\n",
    "    bag_of_words = bagOfbagsUnigramTfIdf[str(genre)]\n",
    "    if (bag_of_words == None):\n",
    "        bag_of_words = {}\n",
    "    words = descriptions[i].split()\n",
    "    for j in range(len(words)):\n",
    "        if (words[j] not in setOfstopWords):\n",
    "            try:\n",
    "                count = bag_of_words[str(words[j])]\n",
    "                count += 1\n",
    "                bag_of_words.update({str(words[j]):count})\n",
    "            except:\n",
    "                bag_of_words[str(words[j])] = 0\n",
    "    bagOfbagsUnigramTfIdf[str(genre)] = bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a49f8f0-eb96-43b3-b2e5-8e54d5fba81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveBayesResultsUnigramTfIdf = []\n",
    "for desc in descriptions_test:\n",
    "    NaiveBayesResultsUnigramTfIdf.append(NaiveBayes(strTobagOfwordsUnigram(desc), bagOfbagsUnigramTfIdf, books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87707ca-e102-4f4a-a921-df04874143aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "overall_accuracy = performanceMeasures (books['genre'],NaiveBayesResultsUnigramTfIdf,\"accuracy\")\n",
    "print('Overall Accuracy:',\"{:.2f}\".format(overall_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e3098b-615d-4f7a-9797-14d13e71fe41",
   "metadata": {},
   "source": [
    "### c) Analyzing effect of the stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b97b6e-69bd-425f-88c0-d32b1d633d01",
   "metadata": {},
   "source": [
    "**Question:** Why might it make sense to remove stop words when interpreting the model? Why might\n",
    "it make sense to keep stop words?\n",
    "\n",
    "**Answer:** It definitely makes more sense to **_remove_** the stop words when interpreting the results of the models. As we seen in part **4.b**, most of the words whose presence most strongly predicts the genre usually comprised of words such as:\n",
    "\n",
    "the, a, and, of, to, as, in, is, her, his\n",
    "\n",
    "Which do not make sense on their own, hence provide no insight to predict the genre of a given book description.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288a0cc9-5152-4e74-86be-1ada8a02a601",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Overall Conclusion for Stopwords' Effect on Model Performance:\n",
    "Although removing the stopwords from the results in first part of 4.b seemed to make the outputs more meaningful by eliminating a high number meaningless stop words in the top 10 list of words with lowest tf-idf score, on the contrary, the performance tests show us that the overall model accuracy usually drops by a significant amount _**(i.e. from 0.15 to 0.13 or from 0.08 to 0.01)**_ when stopwords are removed from the training set, as seen on the below table:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806c6223-c4b1-4252-957b-07aa2c08575f",
   "metadata": {},
   "source": [
    "Method | Stopword | Accuracy \n",
    ":-: |:-: |:-:\n",
    "BoW-unigram | No | 0.15\n",
    "BoW-unigram | Yes | 0.13 \n",
    "BoW-bigram | No | 0.08\n",
    "BoW-bigram | Yes | 0.01 \n",
    "TF-IDF | No | 0.02\n",
    "TF-IDF | Yes | 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bc547e-0cbd-473d-a103-def94c7e6e4b",
   "metadata": {},
   "source": [
    "## 5. Calculation of Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721a8cf4-1995-44f9-919e-12fce80620ba",
   "metadata": {},
   "source": [
    "**We have computed the accuracy of our models to measure the success of our classification\n",
    "methods:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7431cb-fa20-4b18-91a4-e7ebd24b416a",
   "metadata": {},
   "source": [
    "**performanceMeasures** function calculates the overall performance of the models automatically. It calculates the **precision and recall metrics for each genre** as well as the **overall accuracy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bd1447-463f-4d7d-a1a5-8035df84b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performanceMeasures (test_input,test_output,measure=\"accuracy\",genre=\"Fantasy\"):\n",
    "    sample_size = len(test_output)\n",
    "    TP = 0 # True positive\n",
    "    TN = 0 # True negative\n",
    "    FP = 0 # False positive\n",
    "    FN = 0 # False negative\n",
    "    for i in range(sample_size):\n",
    "        if (test_input[i] == test_output[i]):\n",
    "            if (test_output[i] == genre):\n",
    "                TP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "        else:\n",
    "            if (test_output[i] == genre):\n",
    "                FP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "\n",
    "    if (measure == \"accuracy\"):\n",
    "        accuracy = float(TP+TN)/float(sample_size)\n",
    "        #return \"{:.2f}\".format(accuracy)\n",
    "        return accuracy\n",
    "    elif (measure == \"precision\"):\n",
    "        precision = float(TP)/float(TP+FP)\n",
    "        #return \"{:.2f}\".format(precision)\n",
    "        return precision\n",
    "    elif (measure == \"recall\"):\n",
    "        recall = float(TP)/float(TP+FN)\n",
    "        #return \"{:.2f}\".format(recall)\n",
    "        return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8266cb4-8982-49fa-a113-2fcd3072ea89",
   "metadata": {},
   "source": [
    "### Performance Results for Unigram Naive Bayes Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b513f-e637-43a4-9eb5-ea0701d3317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_accuracy = performanceMeasures (books['genre'],NaiveBayesResultsUnigram,\"accuracy\")\n",
    "print('Overall Accuracy:',\"{:.2f}\".format(overall_accuracy))\n",
    "for genre in bagOfbagsUnigram.keys():\n",
    "    recall = performanceMeasures (books['genre'],NaiveBayesResultsUnigram,\"recall\",genre)\n",
    "    precision = performanceMeasures (books['genre'],NaiveBayesResultsUnigram,\"precision\",genre)\n",
    "    print(genre,':')\n",
    "    print('\\tRecall: ',\"{:.2f}\".format(recall))\n",
    "    print('\\tPrecision: ',\"{:.2f}\".format(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbd7cc4-6c4c-4b60-b684-e993996977b8",
   "metadata": {},
   "source": [
    "**strTobagOfwordsBigram** function converts **string** descriptions to **nestedDict** (Bigram) bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be50753f-9a1d-473c-9f86-95f17327f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strTobagOfwordsBigram (string):\n",
    "    bag_of_words = {}\n",
    "    words = string.split()\n",
    "    for j in range(len(words)-1):\n",
    "        word = words[j] + \" \" + words[j+1]\n",
    "        try:\n",
    "            count  = bag_of_test[str(word)]\n",
    "            count += 1\n",
    "            bag_of_test.update({str(word):count})\n",
    "        except:\n",
    "            bag_of_words[str(word)] = 1 \n",
    "    return bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02643a3-23a7-469e-b346-93b6cd3b2d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagOfbagsBigram = dict.fromkeys(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48683213-a74b-4ea5-8e38-d5aea4f1c93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagOfbagsBigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66776fa7-fef0-482b-8587-43d67ccb1ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(descriptions)):\n",
    "    genre = books[\"genre\"][i]\n",
    "    bag_of_words = bagOfbagsBigram[str(genre)]\n",
    "    if (bag_of_words == None):\n",
    "        bag_of_words = {}\n",
    "    words = descriptions[i].split()\n",
    "    for j in range(len(words) - 1):\n",
    "        word = words[j] + \" \" + words[j+1]\n",
    "        try:\n",
    "            count = bag_of_words[str(word)]\n",
    "            count += 1\n",
    "            bag_of_words.update({str(word):count})\n",
    "        except:\n",
    "            bag_of_words[str(word)] = 0\n",
    "    bagOfbagsBigram[str(genre)] = bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f217915-0a60-4737-81da-0f7ccfbb8372",
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveBayesResultsBigram = []\n",
    "for desc in descriptions_test:\n",
    "    NaiveBayesResultsBigram.append(NaiveBayes(strTobagOfwordsBigram(desc), bagOfbagsBigram, books))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72696eb7-ddec-4c6c-a34b-9f4bf685047f",
   "metadata": {},
   "source": [
    "### Performance Results for Bigram Naive Bayes Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23bad39-93d6-4a74-bf94-f2b70512f0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_accuracy = performanceMeasures (books['genre'],NaiveBayesResultsBigram,\"accuracy\")\n",
    "print('Overall Accuracy:',\"{:.2f}\".format(overall_accuracy))\n",
    "for genre in bagOfbagsBigram.keys():\n",
    "    recall = performanceMeasures (books['genre'],NaiveBayesResultsBigram,\"recall\",genre)\n",
    "    precision = performanceMeasures (books['genre'],NaiveBayesResultsBigram,\"precision\",genre)\n",
    "    print(genre,':')\n",
    "    print('\\tRecall: ',\"{:.2f}\".format(recall))\n",
    "    print('\\tPrecision: ',\"{:.2f}\".format(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8768f08f-39e2-4cf9-8a5b-4564c0f8a020",
   "metadata": {},
   "source": [
    "### Performance Comparison of all Methods used in this Report:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55126413-f3fd-4064-a333-1eaaca030b38",
   "metadata": {},
   "source": [
    "Method | Stopword | Accuracy \n",
    ":-: |:-: |:-:\n",
    "BoW-unigram | No | 0.15\n",
    "BoW-unigram | Yes | 0.13 \n",
    "BoW-bigram | No | 0.08\n",
    "BoW-bigram | Yes | 0.01 \n",
    "TF-IDF | No | 0.02\n",
    "TF-IDF | Yes | 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3fb147-1b74-4ae4-9fa8-05029e474c6d",
   "metadata": {},
   "source": [
    "=END OF REPORT=\n",
    "\n",
    "THANK YOU FOR YOUR TIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6413a5b3-22b6-407a-aa09-795247bb8a63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ain311",
   "language": "python",
   "name": "ain311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
